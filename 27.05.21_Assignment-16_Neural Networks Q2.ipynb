{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. \n",
    "    The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.\n",
    "\n",
    "## Problem statement: \n",
    "    predicting turbine energy yield (TEY) using ambient variables as features.\n",
    "\n",
    "    Attribute Information:\n",
    "\n",
    "    The explanations of sensor measurements and their brief statistics are given below.\n",
    "\n",
    "    Variable (Abbr.) Unit Min Max Mean\n",
    "    Ambient temperature (AT) C â€“6.23 37.10 17.71\n",
    "    Ambient pressure (AP) mbar 985.85 1036.56 1013.07\n",
    "    Ambient humidity (AH) (%) 24.08 100.20 77.87\n",
    "    Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93\n",
    "    Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56\n",
    "    Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43\n",
    "    Turbine after temperature (TAT) C 511.04 550.61 546.16\n",
    "    Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06\n",
    "    Turbine energy yield (TEY) MWH 100.02 179.50 133.51\n",
    "    Carbon monoxide (CO) mg/m3 0.00 44.10 2.37\n",
    "    Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('D:\\ExcelR\\Data Science\\Assignments related\\CSV\\gas_turbines.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "df1 = df.drop('TEY',axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>TEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>114.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>111.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>110.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>110.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>111.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX     TEY  \n",
       "0      82.722  114.70  \n",
       "1      82.776  114.72  \n",
       "2      82.468  114.71  \n",
       "3      82.670  114.72  \n",
       "4      82.311  114.72  \n",
       "...       ...     ...  \n",
       "15034  79.559  111.61  \n",
       "15035  79.917  111.78  \n",
       "15036  90.912  110.19  \n",
       "15037  93.227  110.74  \n",
       "15038  92.498  111.58  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(df1),\n",
    "                     df[['TEY']]], axis = 1)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[114.7 ],\n",
       "       [114.72],\n",
       "       [114.71],\n",
       "       ...,\n",
       "       [110.19],\n",
       "       [110.74],\n",
       "       [111.58]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "array = finalDf.values\n",
    "X = array[:,0:10]\n",
    "Y = array[:,10]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10,  activation='relu'))\n",
    "model.add(Dense(8,  activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1053/1053 [==============================] - 12s 9ms/step - loss: 18353.9753 - val_loss: 17209.2656\n",
      "Epoch 2/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18269.0326 - val_loss: 17209.2656\n",
      "Epoch 3/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18358.6379 - val_loss: 17209.2656\n",
      "Epoch 4/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18342.2809 - val_loss: 17209.2656\n",
      "Epoch 5/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18304.5049 - val_loss: 17209.2656\n",
      "Epoch 6/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18303.5863 - val_loss: 17209.2656\n",
      "Epoch 7/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18259.1554 - val_loss: 17209.2656\n",
      "Epoch 8/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18306.3501 - val_loss: 17209.2656\n",
      "Epoch 9/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18324.6611 - val_loss: 17209.2656\n",
      "Epoch 10/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18288.9856 - val_loss: 17209.2656\n",
      "Epoch 11/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18294.1649 - val_loss: 17209.2656\n",
      "Epoch 12/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18343.0259 - val_loss: 17209.2656\n",
      "Epoch 13/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18338.2413 - val_loss: 17209.2656\n",
      "Epoch 14/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18275.2447 - val_loss: 17209.2656\n",
      "Epoch 15/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18284.9968 - val_loss: 17209.2656\n",
      "Epoch 16/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18348.0712 - val_loss: 17209.2656\n",
      "Epoch 17/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18351.1785 - val_loss: 17209.2656\n",
      "Epoch 18/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18284.0733 - val_loss: 17209.2656\n",
      "Epoch 19/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18276.2020 - val_loss: 17209.2656\n",
      "Epoch 20/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18211.7718 - val_loss: 17209.2656\n",
      "Epoch 21/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18315.0279 - val_loss: 17209.2656\n",
      "Epoch 22/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18263.6625 - val_loss: 17209.2656\n",
      "Epoch 23/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18319.3111 - val_loss: 17209.2656\n",
      "Epoch 24/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18324.9691 - val_loss: 17209.2656\n",
      "Epoch 25/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18352.1813 - val_loss: 17209.2656\n",
      "Epoch 26/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18239.0459 - val_loss: 17209.2656\n",
      "Epoch 27/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18325.3222 - val_loss: 17209.2656\n",
      "Epoch 28/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18247.7650 - val_loss: 17209.2656\n",
      "Epoch 29/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18292.9130 - val_loss: 17209.2656\n",
      "Epoch 30/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18396.8723 - val_loss: 17209.2656\n",
      "Epoch 31/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18318.0024 - val_loss: 17209.2656\n",
      "Epoch 32/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18289.0242 - val_loss: 17209.2656\n",
      "Epoch 33/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18423.5033 - val_loss: 17209.2656\n",
      "Epoch 34/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18241.8227 - val_loss: 17209.2656\n",
      "Epoch 35/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18295.9847 - val_loss: 17209.2656\n",
      "Epoch 36/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18314.3632 - val_loss: 17209.2656\n",
      "Epoch 37/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18270.5278 - val_loss: 17209.2656\n",
      "Epoch 38/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18382.8027 - val_loss: 17209.2656\n",
      "Epoch 39/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18288.5532 - val_loss: 17209.2656\n",
      "Epoch 40/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18338.1252 - val_loss: 17209.2656\n",
      "Epoch 41/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18360.0342 - val_loss: 17209.2656\n",
      "Epoch 42/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18386.7780 - val_loss: 17209.2656\n",
      "Epoch 43/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18280.8234 - val_loss: 17209.2656\n",
      "Epoch 44/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18316.3818 - val_loss: 17209.2656\n",
      "Epoch 45/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18328.2402 - val_loss: 17209.2656\n",
      "Epoch 46/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18281.5043 - val_loss: 17209.2656\n",
      "Epoch 47/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18287.6119 - val_loss: 17209.2656\n",
      "Epoch 48/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18285.6099 - val_loss: 17209.2656\n",
      "Epoch 49/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18337.5384 - val_loss: 17209.2656\n",
      "Epoch 50/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18317.6220 - val_loss: 17209.2656\n",
      "Epoch 51/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18302.8382 - val_loss: 17209.2656\n",
      "Epoch 52/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18374.0629 - val_loss: 17209.2656\n",
      "Epoch 53/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18362.3347 - val_loss: 17209.2656\n",
      "Epoch 54/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18340.9134 - val_loss: 17209.2656\n",
      "Epoch 55/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18335.9472 - val_loss: 17209.2656\n",
      "Epoch 56/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18375.5860 - val_loss: 17209.2656\n",
      "Epoch 57/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18371.9434 - val_loss: 17209.2656\n",
      "Epoch 58/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18265.3971 - val_loss: 17209.2656\n",
      "Epoch 59/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18312.2084 - val_loss: 17209.2656\n",
      "Epoch 60/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18318.5350 - val_loss: 17209.2656\n",
      "Epoch 61/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18365.4335 - val_loss: 17209.2656\n",
      "Epoch 62/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18370.8235 - val_loss: 17209.2656\n",
      "Epoch 63/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18337.9239 - val_loss: 17209.2656\n",
      "Epoch 64/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18364.4569 - val_loss: 17209.2656\n",
      "Epoch 65/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18384.8971 - val_loss: 17209.2656\n",
      "Epoch 66/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18295.9696 - val_loss: 17209.2656\n",
      "Epoch 67/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18309.9523 - val_loss: 17209.2656\n",
      "Epoch 68/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18318.1770 - val_loss: 17209.2656\n",
      "Epoch 69/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18307.8341 - val_loss: 17209.2656\n",
      "Epoch 70/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18263.4715 - val_loss: 17209.2656\n",
      "Epoch 71/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18261.5190 - val_loss: 17209.2656\n",
      "Epoch 72/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18247.0724 - val_loss: 17209.2656\n",
      "Epoch 73/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18307.6913 - val_loss: 17209.2656\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18339.4954 - val_loss: 17209.2656\n",
      "Epoch 75/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18255.2866 - val_loss: 17209.2656\n",
      "Epoch 76/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18324.4062 - val_loss: 17209.2656\n",
      "Epoch 77/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18266.7030 - val_loss: 17209.2656\n",
      "Epoch 78/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18347.1438 - val_loss: 17209.2656\n",
      "Epoch 79/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18355.6572 - val_loss: 17209.2656\n",
      "Epoch 80/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18296.0768 - val_loss: 17209.2656\n",
      "Epoch 81/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18292.0847 - val_loss: 17209.2656\n",
      "Epoch 82/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18284.9225 - val_loss: 17209.2656\n",
      "Epoch 83/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18243.5787 - val_loss: 17209.2656\n",
      "Epoch 84/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18331.6243 - val_loss: 17209.2656\n",
      "Epoch 85/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18334.7111 - val_loss: 17209.2656\n",
      "Epoch 86/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18287.5556 - val_loss: 17209.2656\n",
      "Epoch 87/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18339.6117 - val_loss: 17209.2656\n",
      "Epoch 88/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18273.5154 - val_loss: 17209.2656\n",
      "Epoch 89/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18363.3704 - val_loss: 17209.2656\n",
      "Epoch 90/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18330.0934 - val_loss: 17209.2656\n",
      "Epoch 91/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18394.1986 - val_loss: 17209.2656\n",
      "Epoch 92/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18355.8078 - val_loss: 17209.2656\n",
      "Epoch 93/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18339.4766 - val_loss: 17209.2656\n",
      "Epoch 94/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18263.5721 - val_loss: 17209.2656\n",
      "Epoch 95/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18336.2592 - val_loss: 17209.2656\n",
      "Epoch 96/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18342.6256 - val_loss: 17209.2656\n",
      "Epoch 97/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18263.6734 - val_loss: 17209.2656\n",
      "Epoch 98/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18348.4479 - val_loss: 17209.2656\n",
      "Epoch 99/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18268.4578 - val_loss: 17209.2656\n",
      "Epoch 100/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18304.4962 - val_loss: 17209.2656\n",
      "Epoch 101/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18296.9309 - val_loss: 17209.2656\n",
      "Epoch 102/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18266.6906 - val_loss: 17209.2656\n",
      "Epoch 103/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18437.3804 - val_loss: 17209.2656\n",
      "Epoch 104/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18379.1636 - val_loss: 17209.2656\n",
      "Epoch 105/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18320.5429 - val_loss: 17209.2656\n",
      "Epoch 106/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18358.1465 - val_loss: 17209.2656\n",
      "Epoch 107/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18242.4630 - val_loss: 17209.2656\n",
      "Epoch 108/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18370.6409 - val_loss: 17209.2656\n",
      "Epoch 109/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18318.6654 - val_loss: 17209.2656\n",
      "Epoch 110/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18335.7707 - val_loss: 17209.2656\n",
      "Epoch 111/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18282.7690 - val_loss: 17209.2656\n",
      "Epoch 112/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18308.7250 - val_loss: 17209.2656\n",
      "Epoch 113/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18348.8827 - val_loss: 17209.2656\n",
      "Epoch 114/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18317.6616 - val_loss: 17209.2656\n",
      "Epoch 115/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18373.9719 - val_loss: 17209.2656\n",
      "Epoch 116/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18312.5753 - val_loss: 17209.2656\n",
      "Epoch 117/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18323.2326 - val_loss: 17209.2656\n",
      "Epoch 118/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18260.1190 - val_loss: 17209.2656\n",
      "Epoch 119/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18349.1462 - val_loss: 17209.2656\n",
      "Epoch 120/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18340.1549 - val_loss: 17209.2656\n",
      "Epoch 121/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18319.3114 - val_loss: 17209.2656\n",
      "Epoch 122/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18308.4642 - val_loss: 17209.2656\n",
      "Epoch 123/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18275.4806 - val_loss: 17209.2656\n",
      "Epoch 124/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18296.4959 - val_loss: 17209.2656\n",
      "Epoch 125/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18327.9230 - val_loss: 17209.2656\n",
      "Epoch 126/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18363.6385 - val_loss: 17209.2656\n",
      "Epoch 127/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18306.4949 - val_loss: 17209.2656\n",
      "Epoch 128/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18312.9228 - val_loss: 17209.2656\n",
      "Epoch 129/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18348.5423 - val_loss: 17209.2656\n",
      "Epoch 130/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18341.9115 - val_loss: 17209.2656\n",
      "Epoch 131/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18265.7742 - val_loss: 17209.2656\n",
      "Epoch 132/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18302.7973 - val_loss: 17209.2656\n",
      "Epoch 133/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18323.9167 - val_loss: 17209.2656\n",
      "Epoch 134/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18291.6559 - val_loss: 17209.2656\n",
      "Epoch 135/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18382.3342 - val_loss: 17209.2656\n",
      "Epoch 136/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18313.4185 - val_loss: 17209.2656\n",
      "Epoch 137/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18252.9415 - val_loss: 17209.2656\n",
      "Epoch 138/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18352.2801 - val_loss: 17209.2656\n",
      "Epoch 139/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18323.8392 - val_loss: 17209.2656\n",
      "Epoch 140/150\n",
      "1053/1053 [==============================] - 2s 2ms/step - loss: 18293.9363 - val_loss: 17209.2656\n",
      "Epoch 141/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18315.9921 - val_loss: 17209.2656\n",
      "Epoch 142/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18347.8808 - val_loss: 17209.2656\n",
      "Epoch 143/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18356.0203 - val_loss: 17209.2656\n",
      "Epoch 144/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18359.7440 - val_loss: 17209.2656\n",
      "Epoch 145/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18239.1904 - val_loss: 17209.2656\n",
      "Epoch 146/150\n",
      "1053/1053 [==============================] - 2s 1ms/step - loss: 18328.5753 - val_loss: 17209.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18288.2178 - val_loss: 17209.2656\n",
      "Epoch 148/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18299.2270 - val_loss: 17209.2656\n",
      "Epoch 149/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18347.4418 - val_loss: 17209.2656\n",
      "Epoch 150/150\n",
      "1053/1053 [==============================] - 1s 1ms/step - loss: 18441.3149 - val_loss: 17209.2656\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 0s 886us/step - loss: 17989.7305\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('loss')\n",
    "plt.ylabel('epoch')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
